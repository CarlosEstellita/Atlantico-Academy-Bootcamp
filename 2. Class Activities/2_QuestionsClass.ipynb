{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.QuestionsClass.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3GFynLPHjSSVSgNs7e3al",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosEstellita/Atlantico-Academy-Bootcamp/blob/main/2.%20Class%20Activities/2_QuestionsClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second Class Questions"
      ],
      "metadata": {
        "id": "8AqLsdfpUqMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O m√≥dulos foram importados via Google Drive!"
      ],
      "metadata": {
        "id": "2wfkMpuNUuHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjRHfNmHApsj",
        "outputId": "c0932faa-99fd-483d-916d-191c718c0b21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##First Question:"
      ],
      "metadata": {
        "id": "TlyglplEUyQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "contagem de palavras com bag of words"
      ],
      "metadata": {
        "id": "O1_vezJ6U7AA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q_yd-A_AUjUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ecee72-99c0-41b2-8e1f-d89130b61eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 151), ('the', 150), ('.', 89), ('of', 81), (\"''\", 67), ('to', 63), ('a', 60), ('in', 44), ('and', 41), ('(', 40), (')', 40), ('debugging', 39), (':', 31), ('``', 30), ('for', 26), ('is', 25), ('or', 25), ('be', 24), ('{', 22), ('}', 22), ('as', 21), ('system', 19), ('it', 18), ('can', 17), ('software', 16), ('that', 14), ('on', 14), ('tools', 14), ('by', 13), ('process', 12), ('computer', 12), ('are', 12), ('used', 12), ('bug', 11), ('http', 11), ('term', 11), ('such', 11), ('from', 10), ('[', 10), (']', 10), ('problem', 10), ('program', 10), ('debugger', 10), ('<', 10), ('>', 10), ('|', 10), ('programming', 9), ('an', 9), ('not', 9), ('some', 9), ('with', 8), ('was', 8), ('at', 8), ('this', 8), ('code', 8), ('example', 8), ('check', 8), ('have', 7), ('also', 7), ('techniques', 7), ('where', 7), ('which', 7), ('may', 6), ('acm', 6), ('systems', 6), ('more', 6), ('would', 6), ('language', 6), ('make', 6), ('these', 6), ('test', 6), ('ref', 6), ('name=', 6), ('see', 5), ('memory', 5), ('they', 5), ('debug', 5), ('article', 5), (\"'s\", 5), ('but', 5), ('?', 5), ('if', 5), ('problems', 5), ('bugs', 5), ('hardware', 5), ('programmer', 5), ('execution', 5), ('when', 5), ('user', 5), ('after', 5), ('wolf', 5), ('cite', 5), ('anti-debugging', 5), ('control', 4), ('testing', 4), ('&', 4), (';', 4), ('hopper', 4), ('early', 4), ('proceedings', 4), ('errors', 4), ('does', 4), ('use', 4), ('computing', 4), ('1952', 4), ('national', 4), ('impact', 4), ('might', 4), ('all', 4), ('determine', 4), ('s', 4), ('often', 4), ('very', 4), ('source', 4), ('case', 4), ('original', 4), ('tracing', 4), ('different', 4), ('fence', 4), ('algorithm', 4), ('--', 4), ('embedded', 4), ('been', 3), ('about', 3), ('design', 3), ('moth', 3), ('grace', 3), ('she', 3), ('error', 3), ('j.', 3), ('journal', 3), ('p.', 3), ('first', 3), ('//portal.acm.org/citation.cfm', 3), ('meeting', 3), ('common', 3), ('various', 3), ('anomalies', 3), ('avoid', 3), ('made', 3), ('change', 3), ('issues', 3), ('then', 3), ('developers', 3), ('simple', 3), ('tasks', 3), ('analysis', 3), ('breakpoints', 3), ('values', 3), ('languages', 3), ('easier', 3), ('specific', 3), ('useful', 3), ('within', 3), ('detected', 3), ('reproduce', 3), ('crash', 3), ('only', 3), ('using', 3), ('print', 3), ('statements', 3), ('command', 3), ('tron', 3), ('remote', 3), ('information', 3), ('its', 3), ('dump', 3), ('you', 3), ('e.g', 3), ('squeeze', 3), (\"'\", 2), ('operation', 2), ('numerous', 2), ('interactive', 2), ('flow', 2), ('application', 2), ('special', 2), ('detection', 2), ('while', 2), ('changes', 2), ('origin', 2), ('entry', 2), ('mark', 2), ('nbsp', 2), ('ii', 2), ('page', 2), ('terms', 2), ('harvard', 2), ('remarked', 2), ('however', 2), ('technical', 2), ('full', 2), ('discussion', 2), ('computers', 2), ('citation', 2), ('already', 2), ('so', 2), ('letter', 2), ('dr.', 2), ('reference', 2), ('1945', 2), ('royal', 2), ('society', 2), ('time', 2), ('until', 2), ('series', 2), ('1951', 2), ('digital', 2), ('three', 2), ('pittsburgh', 2), ('b.', 2), ('1963', 2), ('compatible', 2), ('time-sharing', 2), ('kidwell', 2), ('elusive', 2), ('history', 2), ('electronic', 2), ('generally', 2), ('detect', 2), ('assess', 2), ('updates', 2), ('words', 2), ('there', 2), (\"''defects\", 2), ('assessment', 2), ('remove', 2), ('important', 2), ('than', 2), ('known', 2), ('existence', 2), ('result', 2), ('appear', 2), ('will', 2), ('how', 2), ('same', 2), ('their', 2), ('complexity', 2), ('data', 2), ('available', 2), ('set', 2), ('exception', 2), ('handling', 2), ('difficult', 2), ('cases', 2), ('needed', 2), ('certain', 2), ('general', 2), ('purpose', 2), ('compiler', 2), ('thus', 2), ('checkers', 2), ('exist', 2), ('checking', 2), ('large', 2), ('do', 2), ('typical', 2), ('variable', 2), ('perform', 2), ('e.g.', 2), ('well', 2), ('low-level', 2), ('firmware', 2), ('task', 2), ('environment', 2), ('simplified', 2), ('file', 2), ('simplification', 2), ('few', 2), ('sufficient', 2), ('manually', 2), ('try', 2), ('parts', 2), ('states', 2), ('variables', 2), ('down', 2), ('visible', 2), ('trace', 2), ('due', 2), ('versions', 2), ('basic', 2), ('caused', 2), ('line', 2), ('state', 2), ('has', 2), ('include', 2), ('stephen', 2), ('gauss', 2), ('now', 2), ('communications', 2), ('one', 2), ('find', 2), ('side', 2), ('snd', 2), ('technique', 2), ('isbn', 2), ('!', 2), ('hit', 2), (\"'em\", 2), ('platforms', 2), ('cpu', 2), ('operating', 2), ('optimize', 2), ('engineering', 2), ('web', 2), ('soft-prot', 2), ('thread', 2), ('blocks', 2), ('word', 2), ('disk', 2), ('url=http', 2), (\"''debugging\", 1), ('finding', 1), ('resolving', 1), ('defects', 1), ('prevent', 1), ('correct', 1), ('books', 1), ('written', 1), ('below', 1), ('#', 1), ('further', 1), ('reading|further', 1), ('reading', 1), ('involves', 1), ('aspects', 1), ('including', 1), ('integration', 1), ('logfile|log', 1), ('files', 1), ('monitoring', 1), ('monitoring|application', 1), ('monitoring|system', 1), ('dumps', 1), ('profiling', 1), ('|profiling', 1), ('statistical', 1), ('tactics', 1), ('improve', 1), ('simplifying', 1), ('log', 1), ('taped', 1), ('popularly', 1), ('attributed', 1), ('admiral', 1), ('1940s', 1), ('//foldoc.org/grace+hopper', 1), ('foldoc', 1), ('working', 1), ('ii|mark', 1), ('university', 1), ('her', 1), ('associates', 1), ('discovered', 1), ('stuck', 1), ('relay', 1), ('thereby', 1), ('impeding', 1), ('whereupon', 1), ('were', 1), ('meaning', 1), ('dates', 1), ('back', 1), ('least', 1), ('1878', 1), ('thomas', 1), ('edison', 1), ('seems', 1), ('aeronautics', 1), ('before', 1), ('entering', 1), ('world', 1), ('indeed', 1), ('interview', 1), ('coining', 1), ('needed|date=july', 1), ('2015', 1), ('fit', 1), ('existing', 1), ('terminology', 1), ('saved', 1), ('robert', 1), ('oppenheimer', 1), ('director', 1), ('wwii', 1), ('atomic', 1), ('bomb', 1), ('manhattan', 1), ('project', 1), ('los', 1), ('alamos', 1), ('nm', 1), ('ernest', 1), ('lawrence', 1), ('uc', 1), ('berkeley', 1), ('dated', 1), ('october', 1), ('27', 1), ('1944', 1), ('//bancroft.berkeley.edu/exhibits/physics/images/bigscience25.jpg', 1), ('regarding', 1), ('recruitment', 1), ('additional', 1), ('staff', 1), ('oxford', 1), ('english', 1), ('dictionary', 1), ('quotes', 1), ('airplane', 1), ('engine', 1), ('aeronautical', 1), ('airforce', 1), ('june', 1), ('50', 1), ('refers', 1), ('aircraft', 1), ('cameras', 1), ('bug|bug', 1), ('found', 1), ('september', 1), ('9', 1), ('1947', 1), ('adopted', 1), ('programmers', 1), ('1950s', 1), ('seminal', 1), ('gills', 1), ('gill', 1), ('//www.jstor.org/stable/98663', 1), ('diagnosis', 1), ('mistakes', 1), ('programmes', 1), ('edsac', 1), ('london', 1), ('mathematical', 1), ('physical', 1), ('sciences', 1), ('vol', 1), ('206', 1), ('no', 1), ('1087', 1), ('22', 1), ('pp', 1), ('538-554', 1), ('earliest', 1), ('in-depth', 1), ('association', 1), ('machinery|acm', 1), ('library', 1), ('papers', 1), ('meetings.robert', 1), ('v.', 1), ('d.', 1), ('campbell', 1), ('id=609784.609786', 1), ('evolution', 1), ('automatic', 1), ('computation', 1), ('p', 1), ('29-32', 1), ('1952.alex', 1), ('orden', 1), ('id=609784.609793', 1), ('solution', 1), ('linear', 1), ('inequalities', 1), ('91-95', 1), ('1952.howard', 1), ('demuth', 1), ('john', 1), ('jackson', 1), ('edmund', 1), ('klein', 1), ('n.', 1), ('metropolis', 1), ('walter', 1), ('orvedahl', 1), ('james', 1), ('h.', 1), ('richardson', 1), ('id=800259.808982', 1), ('maniac', 1), ('toronto', 1), ('13-16', 1), ('two', 1), ('quotation', 1), ('marks', 1), ('enough', 1), ('mentioned', 1), ('passing', 1), ('without', 1), ('explanation', 1), ('1', 1), ('system|ctss', 1), ('manual', 1), ('//www.bitsavers.org/pdf/mit/ctss/ctss_programmersguide.pdf', 1), ('m.i.t', 1), ('press', 1), (\"''stalking\", 1), ('peggy', 1), ('aldrich', 1), ('//ieeexplore.ieee.org/xpl/freeabs_all.jsp', 1), ('tp=', 1), ('arnumber=728224', 1), ('isnumber=15706', 1), ('stalking', 1), ('ieee', 1), ('annals', 1), ('1998.', 1), ('discusses', 1), ('etymology', 1), ('greater', 1), ('detail', 1), ('scope', 1), ('become', 1), ('complex', 1), ('expanded', 1), ('methods', 1), ('schedule', 1), ('patches', 1), ('anomaly', 1), ('discrepancy', 1), ('being', 1), ('neutral', 1), ('defect', 1), ('implication', 1), ('so-called', 1), (\"''errors\", 1), (\"''bugs\", 1), ('must', 1), ('fixed', 1), ('costs', 1), ('instead', 1), (\"''anomaly\", 1), (\"''discrepancy\", 1), ('cost-effective', 1), ('perhaps', 1), ('scheduled', 1), ('new', 1), ('release', 1), ('render', 1), ('unnecessary', 1), ('life-critical', 1), ('mission-critical', 1), ('situation', 1), ('upsetting', 1), ('users', 1), ('long-term', 1), ('living', 1), ('cure', 1), ('worse', 1), ('disease', 1), ('basing', 1), ('decisions', 1), ('acceptability', 1), ('culture', 1), ('zero-defects', 1), ('mandate', 1), ('people', 1), ('tempted', 1), ('deny', 1), ('zero', 1), ('considering', 1), ('collateral', 1), ('cost-versus-benefit', 1), ('broader', 1), ('expand', 1), ('frequency', 1), ('occur', 1), ('help', 1), ('overall', 1), ('video', 1), ('game', 1), ('consoles', 1), ('usually', 1), ('done', 1), ('xbox', 1), ('console', 1), ('|xbox', 1), ('unit', 1), ('intended', 1), ('ranges', 1), ('fixing', 1), ('performing', 1), ('lengthy', 1), ('tiresome', 1), ('collection', 1), ('scheduling', 1), ('skill', 1), ('major', 1), ('factor', 1), ('ability', 1), ('difficulty', 1), ('varies', 1), ('greatly', 1), ('depends', 1), ('extent', 1), (\"''debuggers\", 1), ('debuggers', 1), ('enable', 1), ('monitor', 1), ('|execution', 1), ('stop', 1), ('restart', 1), (\"''debugger\", 1), ('refer', 1), ('person', 1), ('who', 1), ('doing', 1), ('high-level', 1), ('java', 1), ('|java', 1), ('because', 1), ('features', 1), ('real', 1), ('sources', 1), ('erratic', 1), ('behaviour', 1), ('spot', 1), ('c', 1), ('|c', 1), ('assembly', 1), ('language|assembly', 1), ('cause', 1), ('silent', 1), ('corruption', 1), ('initial', 1), ('happened', 1), ('those', 1), ('debugging|memory', 1), ('situations', 1), ('nature', 1), ('take', 1), ('form', 1), (\"''list\", 1), ('static', 1), ('analysis|static', 1), ('look', 1), ('rare', 1), ('rarely', 1), ('picked', 1), ('up', 1), ('interpreter', 1), ('syntax', 1), ('semantic', 1), ('claim', 1), ('able', 1), ('300+', 1), ('unique', 1), ('both', 1), ('commercial', 1), ('free', 1), ('extremely', 1), ('trees', 1), ('impractical', 1), ('walkthroughs', 1), ('dereference', 1), ('occurs', 1), (\"''before\", 1), ('assigned', 1), ('value', 1), ('another', 1), ('strong', 1), ('type', 1), ('require', 1), ('better', 1), ('locating', 1), ('likely', 1), ('versus', 1), ('actual', 1), ('reputation', 1), ('false', 1), ('positives', 1), ('old', 1), ('unix', 1), (\"''lint\", 1), ('tool|lint', 1), ('bioses', 1), ('device', 1), ('drivers', 1), ('instruments', 1), ('oscilloscopes', 1), ('logic', 1), ('analyzers', 1), ('in-circuit', 1), ('emulator|in-circuit', 1), ('emulators', 1), ('ices', 1), ('alone', 1), ('combination', 1), ('ice', 1), ('many', 1), ('normally', 1), ('step', 1), ('attempt', 1), ('non-trivial', 1), ('parallel', 1), ('computing|parallel', 1), ('processes', 1), ('unusual', 1), ('usage', 1), ('reproduced', 1), ('input', 1), ('need', 1), ('|crash', 1), ('parsing', 1), ('lines', 1), ('divide', 1), ('conquer', 1), ('algorithm|divide-and-conquer', 1), ('approach', 1), ('still', 1), ('exists', 1), ('graphical', 1), ('interface|gui', 1), ('skip', 1), ('interaction', 1), ('description', 1), ('remaining', 1), ('actions', 1), ('sufficiently', 1), ('tool', 1), ('examine', 1), ('plus', 1), ('call', 1), ('stack', 1), ('track', 1), ('alternatively', 1), ('|tracing', 1), ('just', 1), ('output', 1), ('points', 1), ('needed|date=february', 1), ('2016', 1), (\"''interactive\", 1), ('anchor|print', 1), ('act', 1), ('watching', 1), ('live', 1), ('recorded', 1), ('indicate', 1), ('sometimes', 1), ('called', 1), ('anchor|printf', 1), ('printf', 1), ('function', 1), ('c.', 1), ('kind', 1), ('turned', 1), ('novice-oriented', 1), ('stood', 1), ('numbers', 1), ('each', 1), ('ran', 1), (\"''remote\", 1), ('running', 1), ('start', 1), ('connects', 1), ('over', 1), ('network', 1), ('retrieve', 1), (\"''post-mortem\", 1), ('|crashed', 1), ('related', 1), ('//www.drdobbs.com/tools/185300443', 1), ('postmortem', 1), ('wormuller', 1), ('dobbs', 1), ('2006', 1), ('and/or', 1), ('core', 1), ('crashed', 1), ('could', 1), ('obtained', 1), ('automatically', 1), ('terminated', 1), ('unhandled', 1), ('programmer-inserted', 1), ('instruction', 1), ('edward', 1), ('described', 1), ('famous', 1), ('1982', 1), ('follows', 1), ('alaska', 1), ('build', 1), ('middle', 1), ('wait', 1), ('howl', 1), ('repeat', 1), ('get', 1), ('point', 1), ('title=', 1), ('pracniques', 1), ('author=e', 1), ('year=1982', 1), ('implemented', 1), ('git', 1), ('|git', 1), ('version', 1), (\"''git\", 1), ('bisect', 1), ('uses', 1), ('above', 1), ('commit', 1), ('management', 1), ('|commit', 1), ('introduced', 1), ('particular', 1), (\"''delta\", 1), ('automating', 1), ('simplification.andreas', 1), ('zeller', 1), ('why', 1), ('programs', 1), ('fail', 1), ('guide', 1), ('systematic', 1), ('/cite', 1), ('morgan', 1), ('kaufmann', 1), ('2005', 1), ('1-55860-866-4', 1), ('rp|p.123', 1), ('redirect', 1), (\"'saff\", 1), (\"''saff\", 1), ('isolating', 1), ('failure', 1), ('progressive', 1), ('inlining', 1), ('failing', 1), ('//www.threeriversinstitute.org/hitemhighhitemlow.html', 1), ('kent', 1), ('beck', 1), ('high', 1), ('low', 1), ('regression', 1), ('saff', 1), ('contrast', 1), ('primary', 1), ('characteristic', 1), ('environments', 1), ('sheer', 1), ('number', 1), ('architectures', 1), ('vendors', 1), ('variants', 1), ('definition', 1), ('general-purpose', 1), ('designs', 1), ('typically', 1), ('developed', 1), ('single', 1), ('small', 1), ('range', 1), ('platform', 1), ('chosen', 1), ('specifically', 1), ('fact', 1), ('life', 1), ('tough', 1), ('makes', 1), ('harder', 1), ('since', 1), ('identify', 1), ('fix', 1), ('logical', 1), ('synchronization', 1), ('collect', 1), ('analyze', 1), ('ways', 1), ('boost', 1), ('performance', 1), ('other', 1), ('characteristics', 1), ('energy', 1), ('consumption', 1), ('reliability', 1), ('real-time', 1), ('response', 1), ('etc.', 1), ('implementation', 1), ('hinders', 1), ('attempts', 1), ('reverse', 1), ('target', 1), ('veracode-antidebugging', 1), ('|url=http', 1), ('//www.veracode.com/blog/2008/12/anti-debugging-series-part-i/', 1), ('|title=anti-debugging', 1), ('-', 1), ('part', 1), ('i', 1), ('|last=shields', 1), ('|first=tyler', 1), ('|date=2008-12-02', 1), ('|work=veracode', 1), ('|accessdate=2009-03-17', 1), ('actively', 1), ('recognized', 1), ('publishers', 1), ('copy', 1), ('protection|copy-protection', 1), ('schemas', 1), ('malware', 1), ('complicate', 1), ('elimination.', 1), ('//people.seas.harvard.edu/~mgagnon/software_protection_through_anti_debugging.pdf', 1), ('protection', 1), ('through', 1), ('michael', 1), ('n', 1), ('gagnon', 1), ('taylor', 1), ('anup', 1), ('ghosh', 1), ('api-based', 1), ('exception-based', 1), ('exceptions', 1), ('interfered', 1), ('whether', 1), ('manipulated', 1), ('modified', 1), ('modifications', 1), ('hardware-', 1), ('register-based', 1), ('registers', 1), ('timing', 1), ('latency', 1), ('taken', 1), ('instructions', 1), ('detecting', 1), ('penalizing', 1), ('/', 1), ('existed', 1), ('microsoft', 1), ('produced', 1), ('message', 1), ('said', 1), ('tree', 1), ('evil', 1), ('bears', 1), ('bitter', 1), ('fruit', 1), ('trashing', 1), ('floppy', 1), ('drive', 1), ('emit', 1), ('alarming', 1), ('noises', 1), ('intent', 1), ('scaring', 1), ('away', 1), ('attempting', 1), ('again.', 1), ('securityengineeringra', 1), ('book', 1), ('//www.cl.cam.ac.uk/~rja14/book.html', 1), ('author=ross', 1), ('anderson', 1), ('title=security', 1), ('=', 1), ('0-471-38922-6', 1), ('page=684', 1), ('toastytech', 1), ('//toastytech.com/guis/word1153.html', 1), ('title=microsoft', 1), ('dos', 1), ('1.15', 1)]\n"
          ]
        }
      ],
      "source": [
        "# Import Counter and word_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "from drive.MyDrive.NLP.src.nlp_utils import get_sample_article\n",
        "\n",
        "article = get_sample_article()\n",
        "\n",
        "# Tokenize the article: tokens\n",
        "tokens = word_tokenize(article)\n",
        "\n",
        "# Convert the tokens into lowercase: lower_tokens\n",
        "lower_tokens = [t.lower() for t in tokens]\n",
        "\n",
        "# Create a Counter with the lowercase tokens: bow_simple\n",
        "bow_simple = Counter(lower_tokens)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow_simple.most_common())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Second Question:"
      ],
      "metadata": {
        "id": "v8ZC3foLWebs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre processing the text\n",
        "\n"
      ],
      "metadata": {
        "id": "3nKwELqvWmP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import WordNetLemmatizer and Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "from drive.MyDrive.NLP.src.nlp_utils import get_wiki_article_lower_tokens, get_english_stop_words\n",
        "\n",
        "\n",
        "lower_tokens = get_wiki_article_lower_tokens()\n",
        "\n",
        "# Retain alphabetic words: alpha_only\n",
        "alpha_only = [t for t in lower_tokens if t.isalpha()]\n",
        "\n",
        "english_stop = get_english_stop_words()\n",
        "# Remove all stop words: no_stops\n",
        "no_stops = [t for t in alpha_only if t not in english_stop]\n",
        "\n",
        "# Instantiate the WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize all tokens into a new list: lemmatized\n",
        "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
        "\n",
        "# Create the bag-of-words: bow\n",
        "bow = Counter(lemmatized)\n",
        "\n",
        "# Print the 10 most common tokens\n",
        "print(bow.most_common(10))"
      ],
      "metadata": {
        "id": "Yke-ofpHWeMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c05fef1-046a-4dc8-9ca5-81cf45a199e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('debugging', 39), ('system', 25), ('software', 16), ('bug', 16), ('problem', 15), ('tool', 15), ('computer', 14), ('process', 13), ('term', 13), ('used', 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Third Question:"
      ],
      "metadata": {
        "id": "sQN7BOsyZOJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction to Gensim"
      ],
      "metadata": {
        "id": "7OkbUDLMZOBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dictionary\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "from drive.MyDrive.NLP.src.nlp_utils import get_pre_process_wiki_articles\n",
        "\n",
        "# Create a Dictionary from the articles: dictionary\n",
        "articles = get_pre_process_wiki_articles()\n",
        "dictionary = Dictionary(articles)\n",
        "\n",
        "# Select the id for \"computer\": computer_id\n",
        "computer_id = dictionary.token2id.get(\"computer\")\n",
        "\n",
        "# Use computer_id with the dictionary to print the word\n",
        "print('the word', dictionary.get(computer_id), 'has index', computer_id, 'in dictionary')\n",
        "\n",
        "# Create a MmCorpus: corpus\n",
        "corpus = [dictionary.doc2bow(article) for article in articles]\n",
        "\n",
        "# Print the first 10 word ids with their frequency counts from the fifth document\n",
        "print(corpus[5][:10])"
      ],
      "metadata": {
        "id": "QrqX61BJZN3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d264e4ac-6f13-4d92-b41b-b62512083008"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the word computer has index 104 in dictionary\n",
            "[(0, 33), (12, 9), (23, 1), (29, 4), (31, 1), (42, 1), (73, 1), (87, 19), (102, 1), (104, 7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fourfh Question:"
      ],
      "metadata": {
        "id": "ZbnZWQW6cj8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gensim and bag-of-words"
      ],
      "metadata": {
        "id": "KeF97MZVcj6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from drive.MyDrive.NLP.src.nlp_utils import get_pre_process_wiki_articles\n",
        "\n",
        "# Create a Dictionary from the articles: dictionary\n",
        "articles = get_pre_process_wiki_articles()\n",
        "dictionary = Dictionary(articles)\n",
        "\n",
        "# Create a MmCorpus: corpus\n",
        "corpus = [dictionary.doc2bow(article) for article in articles]\n",
        "\n",
        "# Get the fifth document in corpus: doc\n",
        "doc = corpus[4]\n",
        "\n",
        "# Sort the doc for frequency: bow_doc\n",
        "bow_doc = sorted(doc, key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Print the top 5 words of the document alongside the count\n",
        "for word_id, word_count in bow_doc[:5]:\n",
        "    print(\"The token \", word_id, \"appears \", word_count, \"times\")\n",
        "\n",
        "# Create the defaultdict: total_word_count\n",
        "total_word_count = defaultdict(int)\n",
        "for word_id, word_count in itertools.chain.from_iterable(corpus):\n",
        "    total_word_count[word_id] += word_count\n",
        "\n",
        "print()\n",
        "# Choose a key between 0 and 10 and show the count with a print function.\n",
        "key = 4\n",
        "print(\"the key\", key, \"in defaultdict has count: \", total_word_count[key], '\\n')\n",
        "\n",
        "# Create a sorted list from the defaultdict: sorted_word_count\n",
        "sorted_word_count = sorted(total_word_count.items(), key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Print the top 5 words across all documents alongside the count\n",
        "for x, q in sorted_word_count[:5]:\n",
        "    print(dictionary.get(x), q)"
      ],
      "metadata": {
        "id": "1s-5uOzKcjrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692f521e-0bfc-4a69-eac4-c6399373b975"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token  0 appears  53 times\n",
            "The token  167 appears  35 times\n",
            "The token  1558 appears  27 times\n",
            "The token  416 appears  16 times\n",
            "The token  1137 appears  11 times\n",
            "\n",
            "the key 4 in defaultdict has count:  1 \n",
            "\n",
            "'' 351\n",
            "software 156\n",
            "computer 153\n",
            "`` 104\n",
            "cite 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fifth Question:"
      ],
      "metadata": {
        "id": "mdPxWRh2hK0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating TF-IDF with gensim"
      ],
      "metadata": {
        "id": "rDQZjYrvhKx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "from drive.MyDrive.NLP.src.nlp_utils import get_pre_process_wiki_articles\n",
        "from gensim.models import TfidfModel\n",
        "\n",
        "# Create a Dictionary from the articles: dictionary\n",
        "articles = get_pre_process_wiki_articles()\n",
        "dictionary = Dictionary(articles)\n",
        "\n",
        "# Create a MmCorpus: corpus\n",
        "corpus = [dictionary.doc2bow(article) for article in articles]\n",
        "\n",
        "# Get the fifth document in corpus: doc\n",
        "doc = corpus[4]\n",
        "\n",
        "# Create a new TfidfModel using the corpus: tfidf\n",
        "tfidf = TfidfModel(corpus)\n",
        "# Calculate the tfidf weights of doc: tfidf_weights\n",
        "tfidf_weights = tfidf[doc]\n",
        "\n",
        "# Print the first five weights\n",
        "print(tfidf_weights[:5])\n",
        "\n",
        "# Sort the weights from highest to lowest: sorted_tfidf_weights\n",
        "sorted_tfidf_weights = sorted(tfidf_weights, key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Print the top 5 weighted words\n",
        "for term_id, weight in sorted_tfidf_weights[:5]:\n",
        "    print(dictionary.get(term_id,), weight)"
      ],
      "metadata": {
        "id": "HnqR0pFLhKnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f34be3-17dd-492e-a928-62b396c07bb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(29, 0.003947336371077938), (34, 0.015722570834963884), (36, 0.012459842594174939), (40, 0.015722570834963884), (49, 0.06289028333985554)]\n",
            "reverse 0.4245094125440249\n",
            "engineering 0.347517588472571\n",
            "3d 0.22545930743311063\n",
            "product 0.14224789608159819\n",
            "chikofsky 0.14091206714569413\n"
          ]
        }
      ]
    }
  ]
}